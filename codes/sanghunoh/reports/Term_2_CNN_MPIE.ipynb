{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Term_2_CNN_MPIE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/SanghunOh/study_machinglearning/blob/main/codes/sanghunoh/reports/Term_2_CNN_MPIE.ipynb",
      "authorship_tag": "ABX9TyNNRy7IASwGCVuUO3FQEUf3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanghunOh/study_machinglearning/blob/main/codes/sanghunoh/reports/Term_2_CNN_MPIE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Connect Drive"
      ],
      "metadata": {
        "id": "brb_gNSQ-Tyg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zl8YlT9398C",
        "outputId": "563a2da5-d3d9-4f81-b9b9-84a77791870f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1tHYgEz3lQF-LmtFPXRgMBDh4UN54qeAs/datas\n"
          ]
        }
      ],
      "source": [
        "path_root = '/content/drive/MyDrive/datas/'\n",
        "\n",
        "# 작업 경로 설정\n",
        "import os\n",
        "os.chdir(path_root)\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -o ./mpie_30_shuffle.zip -d ./mpie_30_shuffle"
      ],
      "metadata": {
        "id": "q_zK6dD69lx7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXG7KRQz-Nax",
        "outputId": "b6547cbb-3f96-4233-8415-7d44d930f128"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataCh4_7.mat\t\t mpie_30_shuffle\n",
            "dataCh4_7.zip\t\t mpie_30_shuffle.zip\n",
            "digitimages_binary.zip\t number_images\n",
            "iris_shuffle.mat\t results_CNN_20222805113027.pickle\n",
            "iris.zip\t\t results_CNN_label_1_20222805113027.pickle\n",
            "matlab_iris_shuffle.mat  results_CNN_label_2_20222805113027.pickle\n",
            "model.png\t\t results_CNN_label_4_20222805113027.pickle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load Dataset"
      ],
      "metadata": {
        "id": "qLUE0VPqLewv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = path_root + 'mpie_30_shuffle/'\n",
        "\n",
        "def loadDatasetFromCSV(_datafilename, _labelfilename, label_column):\n",
        "  _feature_csv = pd.read_csv(path + _datafilename, dtype=np.float32, header=None) # image features of train data\n",
        "  _feature_flatten = _feature_csv.values.flatten()\n",
        "  _feature_reshape = np.reshape(_feature_flatten, (_feature_csv.shape[0], 32,-1))\n",
        "\n",
        "  _label_csv = pd.read_csv(path + _labelfilename, dtype=np.float32, header=None) # labels of train data\n",
        "  # print(f'_label_csv : {_label_csv.shape}')\n",
        "  _label = _label_csv[label_column] # get label you want\n",
        "\n",
        "  return _feature_reshape, _label"
      ],
      "metadata": {
        "id": "wzRrppGEyLWD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# train\n",
        "train_feature_reshape, train_label = loadDatasetFromCSV('Traindata.csv', 'Trainlabel.csv', 0)\n",
        "# test\n",
        "validation_feature_reshape, validation_label = loadDatasetFromCSV('Testdata.csv', 'Testlabel.csv', 0)\n",
        "\n",
        "train_feature_reshape.shape, train_label.shape, validation_feature_reshape.shape, validation_label.shape"
      ],
      "metadata": {
        "id": "bLAz9qj1LwGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed4d4bae-5614-415e-b070-35d9000b23c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_label_csv : (18777, 6)\n",
            "_label_csv : (5086, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((18777, 32, 32), (18777,), (5086, 32, 32), (5086,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(train_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5ckZH8cYAcL",
        "outputId": "b140ad3c-6b47-45e9-9a9c-a6a9bf947152"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
              "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
              "       26., 27., 28., 29.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GjUDklviz51u"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def preprocessDataset(features_reshape, labels, batch_size=64, shuffle_buffer_size=100):\n",
        "  _batch_size = batch_size\n",
        "  _shuffle_buffer_size = shuffle_buffer_size\n",
        "\n",
        "  _features = features_reshape\n",
        "  _labels = labels\n",
        "  _dataset_tensors = tf.data.Dataset.from_tensor_slices((_features, _labels))\n",
        "\n",
        "  if _shuffle_buffer_size == None:\n",
        "    _dataset_tensors = _dataset_tensors.batch(_batch_size)\n",
        "  else :\n",
        "    _dataset_tensors = _dataset_tensors.shuffle(_shuffle_buffer_size).batch(_batch_size)\n",
        "\n",
        "  return _dataset_tensors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = preprocessDataset(train_feature_reshape, train_label)\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "b0iSCMgGOjCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cbb3ba0-3c7c-4ab8-c731-6e6a6419538f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None, 32, 32), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset?"
      ],
      "metadata": {
        "id": "7CJbD5hHSYCU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = preprocessDataset(validation_feature_reshape, validation_label, shuffle_buffer_size=None)\n",
        "validation_dataset"
      ],
      "metadata": {
        "id": "zrUhEcp4PEk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea97c03f-8910-441c-b8c0-142820279b15"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None, 32, 32), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Deep CNN with BatchNormalization"
      ],
      "metadata": {
        "id": "Ibx9ZbXzwthu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filters = 32\n",
        "_filters = filters\n",
        "_min_filters = 16\n",
        "_hidden_layers = int(_filters / _min_filters)\n",
        "for layer in range(_hidden_layers):\n",
        "  print(f'decrease : {_filters}')\n",
        "  _filters = int(_filters/2)\n",
        "  if _filters < _min_filters:\n",
        "    break\n",
        "\n",
        "for layer in range(_hidden_layers):\n",
        "  _filters = int(_filters*2)\n",
        "  if _filters > filters:\n",
        "    break\n",
        "  print(f'increase : {_filters}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6RjrIKspMHq",
        "outputId": "8d97f8dd-efdf-4820-e835-2c2b0ca76bd1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decrease : 32\n",
            "decrease : 16\n",
            "increase : 16\n",
            "increase : 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "category_count = train_label.unique().shape[0]\n",
        "def make_model(_class_cnt, filters=16, _padding='same', _kernel_initializer='he_normal'\n",
        "      , _activation='relu', _optimizer='SGD', _kernel_size = (3,3), _strides = (1,1)\n",
        "      , pool_type='max', batch_normal=True, _pool_size = (2,2), epochs=2, label_class=0):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    _filters = filters\n",
        "    _min_filters = 16\n",
        "    _hidden_layers = int(_filters / _min_filters)\n",
        "\n",
        "    for layer in range(_hidden_layers):\n",
        "      model.add(layers.Conv2D(input_shape = (32, 32, 1), filters = _filters, kernel_size = _kernel_size\n",
        "                              , strides = _strides, padding = _padding, kernel_initializer=_kernel_initializer))\n",
        "      model.add(layers.Activation(_activation))\n",
        "      if batch_normal:\n",
        "        model.add(layers.BatchNormalization())\n",
        "      if pool_type == 'max':\n",
        "        model.add(layers.MaxPooling2D(pool_size = _pool_size, padding = _padding, strides=_strides))\n",
        "      else :\n",
        "        model.add(layers.AveragePooling2D(pool_size = _pool_size, padding = _padding, strides=_strides))\n",
        "\n",
        "      _filters = int(_filters/2)\n",
        "      if _filters < _min_filters:\n",
        "        break\n",
        "\n",
        "    # ?전 Layer에서 filter size 작아져 실행 않됨\n",
        "    # for layer in range(_hidden_layers):\n",
        "    #   _filters = int(_filters*2)\n",
        "    #   if _filters > filters:\n",
        "    #     break\n",
        "    #   model.add(layers.Conv2D(input_shape = (32, 32, 1), filters = _filters, kernel_size = _kernel_size, strides = _strides, padding = _padding, kernel_initializer=_kernel_initializer))\n",
        "    #   model.add(layers.Activation(_activation))\n",
        "    #   if BatchNormal:\n",
        "    #     model.add(layers.BatchNormalization())\n",
        "    #   model.add(layers.MaxPooling2D(pool_size = _pool_size))\n",
        "\n",
        "    # prior layer should be flattend to be connected to dense layers\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation = _activation, kernel_initializer=_kernel_initializer))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(_class_cnt, activation = 'softmax', kernel_initializer=_kernel_initializer))\n",
        "\n",
        "    # adam = optimizers.Adam(lr = 0.001)\n",
        "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = _optimizer, metrics = ['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "2OdDqPX6UWZr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_model(_class_cnt=6, pool_type='max')    \n",
        "# tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, expand_nested=True, show_layer_activations=True) #layer_range=?, "
      ],
      "metadata": {
        "id": "jhkqYUVkKBtq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###callback function for fit time"
      ],
      "metadata": {
        "id": "69PhSLjqmI8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)\n",
        "TimeHistory()"
      ],
      "metadata": {
        "id": "-r_M426PmP5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b06cfe71-02bf-4951-dd50-d66c053a9132"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.TimeHistory at 0x7fb9e712c510>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fit model"
      ],
      "metadata": {
        "id": "1E1Fdq6pnRAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_epochs = 10\n",
        "_batch_size = int(len(list(train_dataset)) / (len(list(train_dataset))/2))   # Just Check Model params quickly\n",
        "# _batch_size = len(list(train_dataset))\n",
        "\n",
        "def model_fit(_param, _train_dataset, _validation_dataset):\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  model = make_model(**_param)\n",
        "  time_callback = TimeHistory()\n",
        "  history = model.fit(_train_dataset, epochs=_param['epochs'], validation_data=_validation_dataset, callbacks=[time_callback], steps_per_epoch=_batch_size)\n",
        "  execution_time = sum(time_callback.times)\n",
        "  return model, history, execution_time, _param"
      ],
      "metadata": {
        "id": "QYn7Q8f311Bi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_class = 0\n",
        "# train\n",
        "train_feature_reshape, train_label = loadDatasetFromCSV('Traindata.csv', 'Trainlabel.csv', label_class)\n",
        "class_cnt = len(np.unique(train_label))\n",
        "# test\n",
        "validation_feature_reshape, validation_label = loadDatasetFromCSV('Testdata.csv', 'Testlabel.csv', label_class)\n",
        "\n",
        "train_dataset = preprocessDataset(train_feature_reshape, train_label)\n",
        "validation_dataset = preprocessDataset(validation_feature_reshape, validation_label, shuffle_buffer_size=None)\n",
        "\n",
        "param = {'_class_cnt':class_cnt, 'epochs':2, 'label_class':label_class, '_kernel_initializer':None\n",
        "         , '_activation':'sigmoid', 'batch_normal':False, '_optimizer':'RMSprop', 'filters':16 , '_padding':'valid'\n",
        "         , 'pool_type':'max', '_kernel_size': (3,3), '_strides': (1,1), '_pool_size': (2,2)}\n",
        "\n",
        "model_fit(param, train_dataset, validation_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU1uwqf8NyEt",
        "outputId": "5e460b96-53da-4a11-a4ea-8afe256a1d67"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_label_csv : (18777, 6)\n",
            "_label_csv : (5086, 6)\n",
            "Epoch 1/2\n",
            "2/2 [==============================] - 4s 2s/step - loss: 3.7637 - accuracy: 0.0391 - val_loss: 3.6548 - val_accuracy: 0.0391\n",
            "Epoch 2/2\n",
            "2/2 [==============================] - 2s 2s/step - loss: 3.8623 - accuracy: 0.0469 - val_loss: 3.6074 - val_accuracy: 0.0391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<keras.engine.sequential.Sequential at 0x7fb9e7232f50>,\n",
              " <keras.callbacks.History at 0x7fb9e70f5dd0>,\n",
              " 6.112790584564209,\n",
              " {'_activation': 'sigmoid',\n",
              "  '_class_cnt': 30,\n",
              "  '_kernel_initializer': None,\n",
              "  '_kernel_size': (3, 3),\n",
              "  '_optimizer': 'RMSprop',\n",
              "  '_padding': 'valid',\n",
              "  '_pool_size': (2, 2),\n",
              "  '_strides': (1, 1),\n",
              "  'batch_normal': False,\n",
              "  'epochs': 2,\n",
              "  'filters': 16,\n",
              "  'label_class': 0,\n",
              "  'pool_type': 'max'})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fit with multi params\n",
        "filters : larger than 16"
      ],
      "metadata": {
        "id": "6NzJoF7tx9Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'_class_cnt':class_cnt, 'epochs':2, 'label_class':label_class, '_kernel_initializer':None\n",
        "         , '_activation':'sigmoid', 'batch_normal':False, '_optimizer':'Nadam', 'filters':16 , '_padding':'same'\n",
        "         , 'pool_type':'average', '_kernel_size': (3,3), '_strides': (1,1), '_pool_size': (2,2)}\n"
      ],
      "metadata": {
        "id": "2rWo9r9qQhWS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# param 6\n",
        "params = list()\n",
        "param_key_list = list(param.keys())\n",
        "epochs_list = [10, 50, 100]\n",
        "_kernel_initializer_list = [None, 'glorot_uniform', 'he_normal']\n",
        "_activation_list = ['sigmoid', 'relu']\n",
        "_optimizer_list= ['Adam', 'Nadam']\n",
        "batch_normal_list = [False, True]\n",
        "filters_list = [16, 32]\n",
        "_padding_list = ['same', 'valid']\n",
        "_kernel_size_list = [(3,3), (5,5)]\n",
        "_strides_list = [(1,1), (3,3)]\n",
        "pool_type_list = ['average', 'max']\n",
        "\n",
        "for filters in filters_list:\n",
        "  for _padding in _padding_list:\n",
        "    for _kernel_initializer in _kernel_initializer_list:\n",
        "      for _activation in _activation_list:\n",
        "        for _optimizer in _optimizer_list:\n",
        "          for batch_normal in batch_normal_list:\n",
        "            for epochs in epochs_list:\n",
        "              for _kernel_size in _kernel_size_list:\n",
        "                for _strides in _strides_list:\n",
        "                  for pool_type in pool_type_list:\n",
        "                    param_dict = dict()\n",
        "                    param_dict['filters'] = filters\n",
        "                    param_dict['_padding'] = _padding\n",
        "                    param_dict['_kernel_initializer'] = _kernel_initializer\n",
        "                    param_dict['_activation'] = _activation\n",
        "                    param_dict['_optimizer'] = _optimizer\n",
        "                    param_dict['batch_normal'] = batch_normal\n",
        "                    param_dict['epochs'] = epochs\n",
        "                    param_dict['_kernel_size'] = _kernel_size\n",
        "                    param_dict['_strides'] = _strides\n",
        "                    param_dict['pool_type'] = pool_type\n",
        "                    # print(param_dict)\n",
        "                    params.append(param_dict)\n",
        "len(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv6FmRH5RJFK",
        "outputId": "03c60b66-e71b-4eeb-c634-b603df6a1955"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2304"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# datetime object containing current date and time\n",
        "now = datetime.now()\n",
        " \n",
        "print(\"now =\", now)\n",
        "\n",
        "# dd/mm/YY H:M:S\n",
        "dt_string = now.strftime(\"%Y%d%m%H%M%S\")\n",
        "print(\"date and time =\", dt_string)\n",
        "\n",
        "import pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TTq4ChAI015",
        "outputId": "c2a9bf2b-e06d-4a4b-d718-78e12359e809"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "now = 2022-05-28 11:50:11.320359\n",
            "date and time = 20222805115011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = params[5:7]\n",
        "label_classes = [1, 2, 4]\n",
        "results_list = list()\n",
        "for label_class in label_classes:\n",
        "  train_feature_reshape, train_label = loadDatasetFromCSV('Traindata.csv', 'Trainlabel.csv', label_class)\n",
        "  class_cnt = len(np.unique(train_label))\n",
        "  # test\n",
        "  validation_feature_reshape, validation_label = loadDatasetFromCSV('Testdata.csv', 'Testlabel.csv', label_class)\n",
        "\n",
        "  train_dataset = preprocessDataset(train_feature_reshape, train_label)\n",
        "  validation_dataset = preprocessDataset(validation_feature_reshape, validation_label, shuffle_buffer_size=None)\n",
        "\n",
        "  results = list()          \n",
        "  for idx, param in enumerate(params):\n",
        "    param['_class_cnt'] = class_cnt\n",
        "    param['label_class'] = label_class\n",
        "    print('-'*5 +'[ '+ str(idx) + ' ]'+ '-'*5 + str(param))\n",
        "    results.append(model_fit(param, train_dataset, validation_dataset))\n",
        "  # save\n",
        "  with open(f'results_CNN_label_{label_class}_{dt_string}.pickle', 'wb') as f:\n",
        "    pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)\n",
        "  results_list = results_list + results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "i1Tnuhc2x5eH",
        "outputId": "d4b3f32a-ad90-4462-87e2-4e9bf2e77f45"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_label_csv : (18777, 6)\n",
            "_label_csv : (5086, 6)\n",
            "_label_csv : (18777, 6)\n",
            "_label_csv : (5086, 6)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-aaf76e536a22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtrain_feature_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadDatasetFromCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Traindata.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Trainlabel.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mclass_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-f160f29f88ae>\u001b[0m in \u001b[0;36mloadDatasetFromCSV\u001b[0;34m(_datafilename, _labelfilename, label_column)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloadDatasetFromCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_datafilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_labelfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0m_feature_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_datafilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# image features of train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0m_feature_flatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_feature_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0m_feature_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_feature_flatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_feature_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m     \"\"\"\n\u001b[1;32m   1422\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save\n",
        "with open(f'results_CNN_{dt_string}.pickle', 'wb') as f:\n",
        "    pickle.dump(results_list, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "nAdPQV3EeZhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###describe model"
      ],
      "metadata": {
        "id": "hzrF4A-v5tQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(results)"
      ],
      "metadata": {
        "id": "AWT1NkM1ciFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "choose_index = 1\n",
        "model = results[choose_index][0]"
      ],
      "metadata": {
        "id": "k2C41njJ50HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, expand_nested=True, show_layer_activations=True) #layer_range=?, "
      ],
      "metadata": {
        "id": "u2i7I3_354Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###drawing history model"
      ],
      "metadata": {
        "id": "ZmJw88aRF63i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = results[choose_index][1]"
      ],
      "metadata": {
        "id": "mzlMqaVi3YD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys(), history.params.keys()"
      ],
      "metadata": {
        "id": "jHt3GTIwfMKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['accuracy'][-1]"
      ],
      "metadata": {
        "id": "9sZZevuaHq1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(_epochs)\n",
        "# acc, list(epochs_range)"
      ],
      "metadata": {
        "id": "m4jMOV3EF--3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bg1qb-PPGASa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluate"
      ],
      "metadata": {
        "id": "d2a4pCYdEwI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = results[choose_index][0]"
      ],
      "metadata": {
        "id": "g8eamLPW32sF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q82yN8mmKIE"
      },
      "outputs": [],
      "source": [
        "model.evaluate(validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_val = model.predict(validation_dataset).argmax(axis=1)\n",
        "predict_val.shape, validation_label.shape"
      ],
      "metadata": {
        "id": "f5h1v6O7FtAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_val[40:46], validation_label[40:46]"
      ],
      "metadata": {
        "id": "ODj0dMrzQcHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "_4fAZ2iqRRVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import seaborn as sns\n",
        "# sns.heatmap(confusion_matrix(validation_label, predict_val), annot=True)"
      ],
      "metadata": {
        "id": "OxmgzrBjbZRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy of the predicted values\n",
        "print(classification_report(validation_label, predict_val)) "
      ],
      "metadata": {
        "id": "02KqSWUObjDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# import warnings\n",
        "# warnings.filterwarnings('always')\n",
        "\n",
        "report = classification_report(validation_label, predict_val, output_dict=True)\n",
        "\n",
        "pd.DataFrame(report).transpose()"
      ],
      "metadata": {
        "id": "bten4DNqEZyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2aRUJeyjEfsS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}