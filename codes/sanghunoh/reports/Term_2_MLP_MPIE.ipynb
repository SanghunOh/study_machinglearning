{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Term_2_MLP_MPIE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1dC0iB_quoTflpUwBm8SRQWMbxouaG5U1",
      "authorship_tag": "ABX9TyPvP4lAU38khRfSnTVdRjVd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanghunOh/study_machinglearning/blob/main/codes/sanghunoh/reports/Term_2_MLP_MPIE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Connect Drive"
      ],
      "metadata": {
        "id": "brb_gNSQ-Tyg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zl8YlT9398C",
        "outputId": "eb12d3cb-7bed-4630-d991-1bd06f0441e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/00.study/10.knou/datas\n"
          ]
        }
      ],
      "source": [
        "path_root = '/content/drive/MyDrive/datas/'\n",
        "\n",
        "# 작업 경로 설정\n",
        "import os\n",
        "os.chdir(path_root)\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -o ./mpie_30_shuffle.zip -d ./mpie_30_shuffle"
      ],
      "metadata": {
        "id": "q_zK6dD69lx7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXG7KRQz-Nax",
        "outputId": "6d110293-9f75-49e3-9ba2-fa67dbe1a298"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataCh4_7.mat\t\tmatlab_iris_shuffle.mat\n",
            "dataCh4_7.zip\t\tmpie_30_shuffle\n",
            "digitimages_binary.zip\tmpie_30_shuffle.zip\n",
            "iris_shuffle.mat\tnumber_images\n",
            "iris.zip\t\tresults_MLP_20222805080015.pickle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load Dataset"
      ],
      "metadata": {
        "id": "qLUE0VPqLewv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = path_root + 'mpie_30_shuffle/'\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def loadDatasetFromCSV(_datafilename, _labelfilename, label_column):\n",
        "  _feature_csv = pd.read_csv(path + _datafilename, dtype=np.float32, header=None) # image features of train data\n",
        "\n",
        "  _label_csv = pd.read_csv(path + _labelfilename, dtype=np.float32, header=None) # labels of train data\n",
        "  _label = _label_csv[label_column] # get label you want\n",
        "\n",
        "  return _feature_csv, _label"
      ],
      "metadata": {
        "id": "wzRrppGEyLWD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "bLAz9qj1LwGC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GjUDklviz51u"
      },
      "outputs": [],
      "source": [
        "def preprocessDataset(label_column):\n",
        "  # train\n",
        "  train_feature_reshape, train_label = loadDatasetFromCSV('Traindata.csv', 'Trainlabel.csv', label_column)\n",
        "  # test\n",
        "  validation_feature_reshape, validation_label = loadDatasetFromCSV('Testdata.csv', 'Testlabel.csv', label_column)\n",
        "\n",
        "  return train_feature_reshape, train_label, validation_feature_reshape, validation_label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_feature, train_label, validation_feature, validation_label = preprocessDataset(1)\n",
        "type(train_feature), train_feature.shape, type(train_label), train_label.shape, validation_feature.shape, validation_label.shape"
      ],
      "metadata": {
        "id": "b0iSCMgGOjCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac9a9a4-4675-41d6-f621-3209fc5eb92b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(pandas.core.frame.DataFrame,\n",
              " (18777, 1024),\n",
              " pandas.core.series.Series,\n",
              " (18777,),\n",
              " (5086, 1024),\n",
              " (5086,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####check model"
      ],
      "metadata": {
        "id": "EakWI3r9aIya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class_cnt = len(np.unique(train_label))\n",
        "# class_cnt\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Dense(256, input_dim=1024, kernel_initializer='glorot_uniform', activation='relu')) \n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(256, input_dim=1024, kernel_initializer='glorot_uniform', activation='relu')) \n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(class_cnt, activation='softmax')) \n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "\n",
        "_epochs = 10\n",
        "model.fit(train_feature, train_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10nMXv_Ad9Z4",
        "outputId": "ada28319-c02f-4f4e-bc70-4c224ab86a38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "587/587 [==============================] - 7s 10ms/step - loss: 1.1351 - accuracy: 0.5933\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f767a426e90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input_layer = layers.Input(shape=(1024,))  # input: 1024 nodes\n",
        "# x = tf.keras.layers.Flatten(name='Flatten')(input_layer)\n",
        "# x = layers.Activation('relu')(layers.Dense(256, input_dim=1024)(x))  # hidden: 256 nodes\n",
        "# x = layers.BatchNormalization()(x)\n",
        "# y = layers.Activation('softmax')(layers.Dense(class_cnt)(x))    # number of output nodes : class_no (it changes depend on label you selected)\n",
        "# model = tf.keras.Model(x, y)\n",
        "# model.compile(loss='sparse_categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "\n",
        "# model.fit(train_feature, train_label)"
      ],
      "metadata": {
        "id": "WvWcJQklaMkY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MPL CNN with BatchNormalization"
      ],
      "metadata": {
        "id": "9MSHrC28O6-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class_cnt = len(np.unique(train_label))\n",
        "class_cnt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCqCX_FxVWV9",
        "outputId": "36b0e927-e08b-4286-d07b-4d17bafa1730"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def make_model(_class_cnt, _hidden_layers=1, dense_count=256, _kernel_initializer='glorot_uniform', _activation='relu', _optimizer='SGD', batch_normal=False, epochs=2, label_class=0):\n",
        "  _model = tf.keras.Sequential()\n",
        "  _model.add(layers.Dense(dense_count, input_dim=1024, kernel_initializer=_kernel_initializer, activation=_activation)) \n",
        "  if batch_normal:\n",
        "    _model.add(layers.BatchNormalization())\n",
        "  for idx in range(_hidden_layers):\n",
        "    _model.add(layers.Dense(dense_count, kernel_initializer=_kernel_initializer, activation=_activation)) \n",
        "    if batch_normal:\n",
        "      _model.add(layers.BatchNormalization())\n",
        "  _model.add(layers.Dense(_class_cnt, activation='softmax')) \n",
        "\n",
        "  _model.compile(loss='sparse_categorical_crossentropy', optimizer=_optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return _model\n",
        "model = make_model(_class_cnt=6)    \n",
        "# tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, expand_nested=True, show_layer_activations=True) #layer_range=?, "
      ],
      "metadata": {
        "id": "yqT3pQgKO92o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###callback function for fit time"
      ],
      "metadata": {
        "id": "69PhSLjqmI8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)\n",
        "TimeHistory()"
      ],
      "metadata": {
        "id": "-r_M426PmP5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "268d74e3-f2bd-4db6-af7a-fca6c353f65a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.TimeHistory at 0x7f7676c3c3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fit model"
      ],
      "metadata": {
        "id": "1E1Fdq6pnRAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = train_feature\n",
        "# _batch_size = int(len(list(rows)) / (len(list(rows))/2))   # Just Check Model params quickly\n",
        "_batch_size = len(list(rows))\n",
        "\n",
        "def model_fit(_param, _dataset):\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  (_train_feature, _train_label, _validation_feature, _validation_label) = _dataset\n",
        "  _param['_class_cnt'] = len(np.unique(_train_label))\n",
        "  print(_param['epochs'], _param['_class_cnt'])\n",
        "\n",
        "  model = make_model(**_param)\n",
        "  time_callback = TimeHistory()\n",
        "  history = model.fit(_train_feature, _train_label, epochs=_param['epochs'], validation_data=(_validation_feature, _validation_label), callbacks=[time_callback], steps_per_epoch=_batch_size)\n",
        "  # history = model.fit(_train_feature, _train_label, epochs=_epochs, callbacks=[time_callback])\n",
        "  execution_time = sum(time_callback.times)\n",
        "  return model, history, execution_time, _param\n",
        "dataset = preprocessDataset(1)  \n",
        "param = {'_hidden_layers':1, 'dense_count':256, '_kernel_initializer':'glorot_uniform', '_activation':'relu', 'batch_normal':False, 'epochs':2}\n",
        "model_fit(param, dataset)  "
      ],
      "metadata": {
        "id": "QYn7Q8f311Bi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d1b923-3994-4986-aed3-834bd2d11177"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 6\n",
            "Epoch 1/2\n",
            "2/2 [==============================] - 1s 744ms/step - loss: 1.7879 - accuracy: 0.1820 - val_loss: 1.5974 - val_accuracy: 0.5319\n",
            "Epoch 2/2\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 1.5460 - accuracy: 0.5646 - val_loss: 1.4977 - val_accuracy: 0.5387\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<keras.engine.sequential.Sequential at 0x7f76fabcc890>,\n",
              " <keras.callbacks.History at 0x7f767a39cfd0>,\n",
              " 2.2066006660461426,\n",
              " {'_activation': 'relu',\n",
              "  '_class_cnt': 6,\n",
              "  '_hidden_layers': 1,\n",
              "  '_kernel_initializer': 'glorot_uniform',\n",
              "  'batch_normal': False,\n",
              "  'dense_count': 256,\n",
              "  'epochs': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fit with multi params"
      ],
      "metadata": {
        "id": "6NzJoF7tx9Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# params = [\n",
        "#           {'_hidden_layers':0, 'dense_count':64, '_kernel_initializer':None, '_activation':'relu', 'batch_normal':False, 'epochs':5},\n",
        "#           {'_hidden_layers':0, 'dense_count':64, '_kernel_initializer':None, '_activation':'relu', 'batch_normal':False, 'epochs':50},\n",
        "#           {'_hidden_layers':0, 'dense_count':64, '_kernel_initializer':None, '_activation':'relu', 'batch_normal':False, 'epochs':100},\n",
        "#           {'_hidden_layers':0, 'dense_count':256, '_kernel_initializer':None, '_activation':'relu', 'batch_normal':False, 'epochs':5},\n",
        "#           {'_hidden_layers':0, 'dense_count':256, '_kernel_initializer':None, '_activation':'relu', 'batch_normal':False, 'epochs':50},\n",
        "#           {'_hidden_layers':0, 'dense_count':256, '_kernel_initializer':None, '_activation':'relu', 'batch_normal':False, 'epochs':100},\n",
        "#           {'_hidden_layers':0, 'dense_count':64, '_kernel_initializer':None, '_activation':'relu', 'batch_normal':False, 'epochs':5},\n",
        "#           {'_hidden_layers':0, 'dense_count':64, '_kernel_initializer':None, '_activation':'relu', 'batch_normal':False, 'epochs':50},\n",
        "#           {'_hidden_layers':0, 'dense_count':64, '_kernel_initializer':None, '_activation':'relu', 'batch_normal':False, 'epochs':100},\n",
        "#           ]"
      ],
      "metadata": {
        "id": "XXtedM988zpn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# param 6\n",
        "params = list()\n",
        "param_key_list = list(param.keys())\n",
        "_hidden_layers_list = [0, 5, 10]\n",
        "dense_count_list = [64, 256]\n",
        "_kernel_initializer_list = [None, 'glorot_uniform']\n",
        "_activation_list = ['sigmoid', 'relu']\n",
        "_optimizer_list= ['SGD', 'Adam']\n",
        "batch_normal_list = [False, True]\n",
        "epochs_list = [10, 50, 100, 500]\n",
        "\n",
        "for _hidden_layers in _hidden_layers_list:\n",
        "  for dense_count in dense_count_list:\n",
        "    for _kernel_initializer in _kernel_initializer_list:\n",
        "      for _activation in _activation_list:\n",
        "        for _optimizer in _optimizer_list:\n",
        "          for batch_normal in batch_normal_list:\n",
        "            for epochs in epochs_list:\n",
        "              param_dict = dict()\n",
        "              param_dict['_hidden_layers'] = _hidden_layers\n",
        "              param_dict['dense_count'] = dense_count\n",
        "              param_dict['_kernel_initializer'] = _kernel_initializer\n",
        "              param_dict['_activation'] = _activation\n",
        "              param_dict['_optimizer'] = _optimizer\n",
        "              param_dict['batch_normal'] = batch_normal\n",
        "              param_dict['epochs'] = epochs\n",
        "              # print(param_dict)\n",
        "              params.append(param_dict)\n",
        "param_dict              "
      ],
      "metadata": {
        "id": "qSHV1HA58Mw1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_classes = [0, 3, 5]\n",
        "for label in label_classes:\n",
        "  dataset = preprocessDataset(label)\n",
        "  results = list()          \n",
        "  for idx, param in enumerate(params):\n",
        "    param['label_class'] = label\n",
        "    print('-'*5 +'[ '+ str(idx) + ' ]'+ '-'*5 + str(param))\n",
        "    results.append(model_fit(param, dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1Tnuhc2x5eH",
        "outputId": "ad330239-1ab2-4157-f027-ed6c183449c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----[ 0 ]-----{'_hidden_layers': 0, 'dense_count': 64, '_kernel_initializer': None, '_activation': 'sigmoid', '_optimizer': 'SGD', 'batch_normal': False, 'epochs': 10, 'label_class': 0}\n",
            "10 30\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 956ms/step - loss: 3.5724 - accuracy: 0.0564 - val_loss: 3.5672 - val_accuracy: 0.0588\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 1s 812ms/step - loss: 3.5659 - accuracy: 0.0570 - val_loss: 3.5610 - val_accuracy: 0.0584\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 1s 722ms/step - loss: 3.5597 - accuracy: 0.0573 - val_loss: 3.5549 - val_accuracy: 0.0566\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 1s 665ms/step - loss: 3.5537 - accuracy: 0.0574 - val_loss: 3.5491 - val_accuracy: 0.0568\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 1s 537ms/step - loss: 3.5479 - accuracy: 0.0577 - val_loss: 3.5436 - val_accuracy: 0.0568\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 1s 676ms/step - loss: 3.5423 - accuracy: 0.0576 - val_loss: 3.5382 - val_accuracy: 0.0572\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 1s 516ms/step - loss: 3.5370 - accuracy: 0.0578 - val_loss: 3.5330 - val_accuracy: 0.0574\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 1s 581ms/step - loss: 3.5318 - accuracy: 0.0579 - val_loss: 3.5280 - val_accuracy: 0.0586\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 1s 567ms/step - loss: 3.5268 - accuracy: 0.0578 - val_loss: 3.5232 - val_accuracy: 0.0584\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 1s 877ms/step - loss: 3.5220 - accuracy: 0.0578 - val_loss: 3.5185 - val_accuracy: 0.0582\n",
            "-----[ 1 ]-----{'_hidden_layers': 0, 'dense_count': 64, '_kernel_initializer': None, '_activation': 'sigmoid', '_optimizer': 'SGD', 'batch_normal': False, 'epochs': 50, 'label_class': 0}\n",
            "50 30\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 3.5891 - accuracy: 0.0390 - val_loss: 3.5825 - val_accuracy: 0.0379\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 1s 992ms/step - loss: 3.5798 - accuracy: 0.0390 - val_loss: 3.5736 - val_accuracy: 0.0379\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 1s 835ms/step - loss: 3.5711 - accuracy: 0.0390 - val_loss: 3.5653 - val_accuracy: 0.0379\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 1s 851ms/step - loss: 3.5629 - accuracy: 0.0390 - val_loss: 3.5574 - val_accuracy: 0.0379\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 1s 331ms/step - loss: 3.5552 - accuracy: 0.0390 - val_loss: 3.5500 - val_accuracy: 0.0379\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 1s 608ms/step - loss: 3.5479 - accuracy: 0.0390 - val_loss: 3.5430 - val_accuracy: 0.0379\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 1s 509ms/step - loss: 3.5410 - accuracy: 0.0390 - val_loss: 3.5363 - val_accuracy: 0.0379\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 1s 519ms/step - loss: 3.5344 - accuracy: 0.0390 - val_loss: 3.5300 - val_accuracy: 0.0379\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 1s 497ms/step - loss: 3.5282 - accuracy: 0.0390 - val_loss: 3.5240 - val_accuracy: 0.0379\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 1s 374ms/step - loss: 3.5223 - accuracy: 0.0390 - val_loss: 3.5183 - val_accuracy: 0.0379\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 1s 436ms/step - loss: 3.5167 - accuracy: 0.0390 - val_loss: 3.5129 - val_accuracy: 0.0379\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 312ms/step - loss: 3.5113 - accuracy: 0.0390 - val_loss: 3.5077 - val_accuracy: 0.0379\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 329ms/step - loss: 3.5062 - accuracy: 0.0390 - val_loss: 3.5028 - val_accuracy: 0.0379\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 1s 429ms/step - loss: 3.5013 - accuracy: 0.0390 - val_loss: 3.4981 - val_accuracy: 0.0379\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 301ms/step - loss: 3.4967 - accuracy: 0.0390 - val_loss: 3.4936 - val_accuracy: 0.0379\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 1s 420ms/step - loss: 3.4922 - accuracy: 0.0390 - val_loss: 3.4893 - val_accuracy: 0.0379\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 414ms/step - loss: 3.4880 - accuracy: 0.0390 - val_loss: 3.4852 - val_accuracy: 0.0379\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 325ms/step - loss: 3.4839 - accuracy: 0.0390 - val_loss: 3.4812 - val_accuracy: 0.0379\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 1s 435ms/step - loss: 3.4800 - accuracy: 0.0390 - val_loss: 3.4775 - val_accuracy: 0.0379\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 1s 425ms/step - loss: 3.4762 - accuracy: 0.0390 - val_loss: 3.4738 - val_accuracy: 0.0379\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 313ms/step - loss: 3.4726 - accuracy: 0.0390 - val_loss: 3.4703 - val_accuracy: 0.0379\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 1s 432ms/step - loss: 3.4692 - accuracy: 0.0390 - val_loss: 3.4670 - val_accuracy: 0.0379\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 292ms/step - loss: 3.4658 - accuracy: 0.0389 - val_loss: 3.4637 - val_accuracy: 0.0379\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 297ms/step - loss: 3.4626 - accuracy: 0.0389 - val_loss: 3.4606 - val_accuracy: 0.0379\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 285ms/step - loss: 3.4595 - accuracy: 0.0388 - val_loss: 3.4577 - val_accuracy: 0.0381\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 312ms/step - loss: 3.4566 - accuracy: 0.0387 - val_loss: 3.4548 - val_accuracy: 0.0381\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 1s 431ms/step - loss: 3.4537 - accuracy: 0.0385 - val_loss: 3.4520 - val_accuracy: 0.0381\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 1s 428ms/step - loss: 3.4509 - accuracy: 0.0383 - val_loss: 3.4493 - val_accuracy: 0.0379\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 327ms/step - loss: 3.4483 - accuracy: 0.0382 - val_loss: 3.4467 - val_accuracy: 0.0378\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 1s 430ms/step - loss: 3.4457 - accuracy: 0.0379 - val_loss: 3.4442 - val_accuracy: 0.0374\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 1s 434ms/step - loss: 3.4432 - accuracy: 0.0376 - val_loss: 3.4418 - val_accuracy: 0.0372\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 1s 429ms/step - loss: 3.4408 - accuracy: 0.0374 - val_loss: 3.4395 - val_accuracy: 0.0366\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 1s 416ms/step - loss: 3.4385 - accuracy: 0.0373 - val_loss: 3.4372 - val_accuracy: 0.0364\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 1s 432ms/step - loss: 3.4362 - accuracy: 0.0370 - val_loss: 3.4351 - val_accuracy: 0.0360\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 1s 434ms/step - loss: 3.4341 - accuracy: 0.0366 - val_loss: 3.4329 - val_accuracy: 0.0360\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 1s 431ms/step - loss: 3.4319 - accuracy: 0.0363 - val_loss: 3.4309 - val_accuracy: 0.0356\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 1s 426ms/step - loss: 3.4299 - accuracy: 0.0363 - val_loss: 3.4289 - val_accuracy: 0.0356\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 1s 429ms/step - loss: 3.4279 - accuracy: 0.0361 - val_loss: 3.4270 - val_accuracy: 0.0356\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 1s 429ms/step - loss: 3.4260 - accuracy: 0.0359 - val_loss: 3.4251 - val_accuracy: 0.0358\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 306ms/step - loss: 3.4241 - accuracy: 0.0356 - val_loss: 3.4233 - val_accuracy: 0.0356\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 306ms/step - loss: 3.4223 - accuracy: 0.0356 - val_loss: 3.4216 - val_accuracy: 0.0354\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 293ms/step - loss: 3.4206 - accuracy: 0.0354 - val_loss: 3.4199 - val_accuracy: 0.0358\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 309ms/step - loss: 3.4189 - accuracy: 0.0351 - val_loss: 3.4182 - val_accuracy: 0.0356\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 1s 417ms/step - loss: 3.4172 - accuracy: 0.0347 - val_loss: 3.4166 - val_accuracy: 0.0358\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 322ms/step - loss: 3.4156 - accuracy: 0.0347 - val_loss: 3.4151 - val_accuracy: 0.0354\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 319ms/step - loss: 3.4141 - accuracy: 0.0346 - val_loss: 3.4135 - val_accuracy: 0.0348\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 320ms/step - loss: 3.4125 - accuracy: 0.0344 - val_loss: 3.4121 - val_accuracy: 0.0342\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 318ms/step - loss: 3.4111 - accuracy: 0.0342 - val_loss: 3.4106 - val_accuracy: 0.0344\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 1s 430ms/step - loss: 3.4096 - accuracy: 0.0339 - val_loss: 3.4092 - val_accuracy: 0.0344\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 289ms/step - loss: 3.4082 - accuracy: 0.0335 - val_loss: 3.4079 - val_accuracy: 0.0338\n",
            "-----[ 2 ]-----{'_hidden_layers': 0, 'dense_count': 64, '_kernel_initializer': None, '_activation': 'sigmoid', '_optimizer': 'SGD', 'batch_normal': False, 'epochs': 100, 'label_class': 0}\n",
            "100 30\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 497ms/step - loss: 3.6064 - accuracy: 0.0295 - val_loss: 3.5960 - val_accuracy: 0.0313\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 1s 428ms/step - loss: 3.5943 - accuracy: 0.0296 - val_loss: 3.5845 - val_accuracy: 0.0311\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 1s 429ms/step - loss: 3.5829 - accuracy: 0.0295 - val_loss: 3.5738 - val_accuracy: 0.0317\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 325ms/step - loss: 3.5723 - accuracy: 0.0297 - val_loss: 3.5638 - val_accuracy: 0.0320\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 322ms/step - loss: 3.5624 - accuracy: 0.0296 - val_loss: 3.5545 - val_accuracy: 0.0317\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 1s 432ms/step - loss: 3.5531 - accuracy: 0.0298 - val_loss: 3.5457 - val_accuracy: 0.0328\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 1s 446ms/step - loss: 3.5444 - accuracy: 0.0299 - val_loss: 3.5375 - val_accuracy: 0.0330\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 1s 426ms/step - loss: 3.5362 - accuracy: 0.0299 - val_loss: 3.5297 - val_accuracy: 0.0332\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 305ms/step - loss: 3.5285 - accuracy: 0.0302 - val_loss: 3.5224 - val_accuracy: 0.0332\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 301ms/step - loss: 3.5212 - accuracy: 0.0302 - val_loss: 3.5155 - val_accuracy: 0.0336\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 1s 429ms/step - loss: 3.5144 - accuracy: 0.0295 - val_loss: 3.5091 - val_accuracy: 0.0338\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 316ms/step - loss: 3.5079 - accuracy: 0.0295 - val_loss: 3.5029 - val_accuracy: 0.0332\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 318ms/step - loss: 3.5018 - accuracy: 0.0302 - val_loss: 3.4971 - val_accuracy: 0.0334\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 1s 433ms/step - loss: 3.4960 - accuracy: 0.0302 - val_loss: 3.4916 - val_accuracy: 0.0326\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 1s 432ms/step - loss: 3.4905 - accuracy: 0.0308 - val_loss: 3.4864 - val_accuracy: 0.0344\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 323ms/step - loss: 3.4853 - accuracy: 0.0324 - val_loss: 3.4815 - val_accuracy: 0.0354\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 1s 413ms/step - loss: 3.4804 - accuracy: 0.0337 - val_loss: 3.4768 - val_accuracy: 0.0372\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 1s 419ms/step - loss: 3.4757 - accuracy: 0.0355 - val_loss: 3.4724 - val_accuracy: 0.0395\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 319ms/step - loss: 3.4713 - accuracy: 0.0373 - val_loss: 3.4681 - val_accuracy: 0.0405\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 1s 426ms/step - loss: 3.4670 - accuracy: 0.0381 - val_loss: 3.4641 - val_accuracy: 0.0423\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 1s 413ms/step - loss: 3.4630 - accuracy: 0.0400 - val_loss: 3.4603 - val_accuracy: 0.0448\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 1s 415ms/step - loss: 3.4592 - accuracy: 0.0409 - val_loss: 3.4566 - val_accuracy: 0.0458\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 1s 437ms/step - loss: 3.4555 - accuracy: 0.0423 - val_loss: 3.4531 - val_accuracy: 0.0470\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 310ms/step - loss: 3.4520 - accuracy: 0.0440 - val_loss: 3.4498 - val_accuracy: 0.0470\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 310ms/step - loss: 3.4486 - accuracy: 0.0448 - val_loss: 3.4466 - val_accuracy: 0.0486\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 1s 442ms/step - loss: 3.4454 - accuracy: 0.0462 - val_loss: 3.4436 - val_accuracy: 0.0497\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 1s 427ms/step - loss: 3.4424 - accuracy: 0.0469 - val_loss: 3.4407 - val_accuracy: 0.0503\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 1s 451ms/step - loss: 3.4395 - accuracy: 0.0482 - val_loss: 3.4379 - val_accuracy: 0.0505\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 316ms/step - loss: 3.4367 - accuracy: 0.0484 - val_loss: 3.4352 - val_accuracy: 0.0501\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 1s 452ms/step - loss: 3.4340 - accuracy: 0.0488 - val_loss: 3.4327 - val_accuracy: 0.0501\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 327ms/step - loss: 3.4314 - accuracy: 0.0492 - val_loss: 3.4302 - val_accuracy: 0.0490\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - ETA: 0s - loss: 3.4289 - accuracy: 0.0489"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# datetime object containing current date and time\n",
        "now = datetime.now()\n",
        " \n",
        "print(\"now =\", now)\n",
        "\n",
        "# dd/mm/YY H:M:S\n",
        "dt_string = now.strftime(\"%Y%d%m%H%M%S\")\n",
        "print(\"date and time =\", dt_string)\n",
        "\n",
        "import pickle\n",
        "# save\n",
        "with open(f'results_MLP_{dt_string}.pickle', 'wb') as f:\n",
        "    pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "9TTq4ChAI015"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}